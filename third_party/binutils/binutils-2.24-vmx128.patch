diff -u -P -r gas/config/tc-ppc.c gas/config/tc-ppc.c
--- gas/config/tc-ppc.c	2013-11-18 00:40:15.000000000 -0800
+++ gas/config/tc-ppc.c	2014-09-04 21:30:09.519546700 -0700
@@ -1294,6 +1294,7 @@
 -many                   generate code for any architecture (PWR/PWRX/PPC)\n"));
   fprintf (stream, _("\
 -maltivec               generate code for AltiVec\n\
+-mvmx128                generate code for VMX128 extension\n\
 -mvsx                   generate code for Vector-Scalar (VSX) instructions\n\
 -mhtm                   generate code for Hardware Transactional Memory\n\
 -me300                  generate code for PowerPC e300 family\n\
diff -u -P -r include/opcode/ppc.h include/opcode/ppc.h
--- include/opcode/ppc.h	2013-11-04 07:33:39.000000000 -0800
+++ include/opcode/ppc.h	2014-09-04 21:30:39.253246900 -0700
@@ -191,6 +191,9 @@
 /* Opcode is only supported by Power8 architecture.  */
 #define PPC_OPCODE_POWER8     0x2000000000ull
 
+/* Opcode is supported by VMX128 Vector Extension */
+#define PPC_OPCODE_VMX_128   0x4000000000ull
+
 /* Opcode which is supported by the Hardware Transactional Memory extension.  */
 /* Currently, this is the same as the POWER8 mask.  If another cpu comes out
    that isn't a superset of POWER8, we can define this to its own mask.  */
diff -u -P -r opcodes/ppc-dis.c opcodes/ppc-dis.c
--- opcodes/ppc-dis.c	2013-11-04 07:33:40.000000000 -0800
+++ opcodes/ppc-dis.c	2014-09-04 21:31:23.076984600 -0700
@@ -89,6 +89,8 @@
     0 },
   { "altivec", (PPC_OPCODE_PPC),
     PPC_OPCODE_ALTIVEC | PPC_OPCODE_ALTIVEC2 },
+  { "vmx128", (PPC_OPCODE_PPC),
+    PPC_OPCODE_VMX_128 },
   { "any",     0,
     PPC_OPCODE_ANY },
   { "booke",   (PPC_OPCODE_PPC | PPC_OPCODE_BOOKE),
diff -u -P -r opcodes/ppc-opc.c opcodes/ppc-opc.c
--- opcodes/ppc-opc.c	2013-11-04 07:33:40.000000000 -0800
+++ opcodes/ppc-opc.c	2014-09-04 21:35:25.869982900 -0700
@@ -117,6 +117,14 @@
 static long extract_vleui (unsigned long, ppc_cpu_t, int *);
 static unsigned long insert_vleil (unsigned long, long, ppc_cpu_t, const char **);
 static long extract_vleil (unsigned long, ppc_cpu_t, int *);
+static unsigned long insert_vds128 (unsigned long, long, ppc_cpu_t, const char **);
+static long extract_vds128 (unsigned long, ppc_cpu_t, int *);
+static unsigned long insert_va128 (unsigned long, long, ppc_cpu_t, const char **);
+static long extract_va128 (unsigned long, ppc_cpu_t, int *);
+static unsigned long insert_vb128 (unsigned long, long, ppc_cpu_t, const char **);
+static long extract_vb128 (unsigned long, ppc_cpu_t, int *);
+static unsigned long insert_vperm (unsigned long, long, ppc_cpu_t, const char **);
+static long extract_vperm (unsigned long, ppc_cpu_t, int *);
 
 /* The operands table.
 
@@ -685,8 +693,43 @@
 #define VS VD
   { 0x1f, 21, NULL, NULL, PPC_OPERAND_VR },
 
-  /* The SIMM field in a VX form instruction, and TE in Z form.  */
-#define SIMM VD + 1
+  /* The VD128 or VS128 field in a VA, VX, VXR or X form instruction. */
+#define VD128 VD + 1
+#define VS128 VD128
+#define VD128_MASK (0x1f << 21)
+  { 7, 0, insert_vds128, extract_vds128, PPC_OPERAND_VR },
+
+  /* The VA128 field in a VA, VX, VXR or X form instruction. */
+#define VA128 VD128 + 1
+#define VA128_MASK (0x1f << 21)
+  { 7, 0, insert_va128, extract_va128, PPC_OPERAND_VR },
+
+  /* The VB128 field in a VA, VX, VXR or X form instruction. */
+#define VB128 VA128 + 1
+#define VB128_MASK (0x1f << 21)
+  { 7, 0, insert_vb128, extract_vb128, PPC_OPERAND_VR },
+
+  /* The VC128 field in a VA, VX, VXR or X form instruction. */
+#define VC128 VB128 + 1
+#define VC128_MASK (0x1f << 21)
+  { 3, 6, NULL, NULL, PPC_OPERAND_VR },
+
+  /* The VPERM field in a VPERM128 form instruction. */
+#define VPERM128 VC128 + 1
+#define VPERM_MASK (0x1f << 21)
+  { 8, 0, insert_vperm, extract_vperm, 0 },
+
+#define VD3D0 VPERM128 + 1
+  { 3, 18, NULL, NULL, 0 },
+
+#define VD3D1 VD3D0 + 1
+  { 2, 16, NULL, NULL, 0 },
+
+#define VD3D2 VD3D1 + 1
+  { 2, 6, NULL, NULL, 0 },
+
+   /* The SIMM field in a VX form instruction, and TE in Z form.  */
+#define SIMM VD3D2 + 1
 #define TE SIMM
   { 0x1f, 16, NULL, NULL, PPC_OPERAND_SIGNED},
 
@@ -2102,6 +2145,84 @@
   return ((insn >> 5) & 0xf800) | (insn & 0x7ff);
 }
 
+/* The VD128 or VS128 field in an VX128 form instruction.  This is split.  */
+
+static unsigned long
+insert_vds128 (unsigned long insn,
+    long value,
+    ppc_cpu_t dialect ATTRIBUTE_UNUSED,
+    const char **errmsg ATTRIBUTE_UNUSED)
+{
+
+  return insn | ((value & 0x60) >> 3) | ((value & 0x1f) << 21);
+}
+
+static long
+extract_vds128 (unsigned long insn,
+     ppc_cpu_t dialect ATTRIBUTE_UNUSED,
+     int *invalid ATTRIBUTE_UNUSED)
+{
+  return ((insn << 3) & 0x60) | ((insn >> 21) & 0x1f);
+}
+
+/* The VA128 field in an VX128 form instruction.  This is split.  */
+
+static unsigned long
+insert_va128 (unsigned long insn,
+    long value,
+    ppc_cpu_t dialect ATTRIBUTE_UNUSED,
+    const char **errmsg ATTRIBUTE_UNUSED)
+{
+  return insn | ((value & 0x40) << 4) | (value & 0x20)
+    | ((value & 0x1f) << 16);
+}
+
+static long
+extract_va128 (unsigned long insn,
+     ppc_cpu_t dialect ATTRIBUTE_UNUSED,
+     int *invalid ATTRIBUTE_UNUSED)
+{
+  return ((insn >> 4) & 0x40) | (insn & 0x20) | ((insn >> 16) & 0x1f);
+}
+
+/* The VB128 field in an VX128 form instruction.  This is split.  */
+
+static unsigned long
+insert_vb128 (unsigned long insn,
+    long value,
+    ppc_cpu_t dialect ATTRIBUTE_UNUSED,
+    const char **errmsg ATTRIBUTE_UNUSED)
+{
+  return insn | ((value & 0x60) >> 5) | ((value & 0x1f) << 11);
+}
+
+static long
+extract_vb128 (unsigned long insn,
+     ppc_cpu_t dialect ATTRIBUTE_UNUSED,
+     int *invalid ATTRIBUTE_UNUSED)
+{
+  return ((insn << 5) & 0x60) | ((insn >> 11) & 0x1f);
+}
+
+/* The VPERM field in an VX128 form instruction.  This is split.  */
+
+static unsigned long
+insert_vperm (unsigned long insn,
+    long value,
+    ppc_cpu_t dialect ATTRIBUTE_UNUSED,
+    const char **errmsg ATTRIBUTE_UNUSED)
+{
+  return insn | ((value & 0xe0) << 1) | ((value & 0x1f) << 16);
+}
+
+static long
+extract_vperm (unsigned long insn,
+     ppc_cpu_t dialect ATTRIBUTE_UNUSED,
+     int *invalid ATTRIBUTE_UNUSED)
+{
+  return ((insn >> 1) & 0xe0) | ((insn >> 16) & 0x1f);
+}
+
 
 /* Macros used to form opcodes.  */
 
@@ -2359,6 +2480,39 @@
 /* The mask for a VXR form instruction.  */
 #define VXR_MASK VXR(0x3f, 0x3ff, 1)
 
+/* An VX128 form instruction. */
+#define VX128(op, xop) (OP (op) | (((unsigned long)(xop)) & 0x3d0))
+
+/* The mask for an VX form instruction. */
+#define VX128_MASK VX(0x3f, 0x3d0)
+
+/* An VX128 form instruction. */
+#define VX128_1(op, xop) (OP (op) | (((unsigned long)(xop)) & 0x7f3))
+
+/* The mask for an VX form instruction. */
+#define VX128_1_MASK VX(0x3f, 0x7f3)
+
+/* An VX128 form instruction. */
+#define VX128_2(op, xop) (OP (op) | (((unsigned long)(xop)) & 0x210))
+
+/* The mask for an VX form instruction. */
+#define VX128_2_MASK VX(0x3f, 0x210)
+
+/* An VX128 form instruction. */
+#define VX128_3(op, xop) (OP (op) | (((unsigned long)(xop)) & 0x7f0))
+
+/* The mask for an VX form instruction. */
+#define VX128_3_MASK VX(0x3f, 0x7f0)
+
+#define VX128_P(op, xop) (OP (op) | (((unsigned long)(xop)) & 0x630))
+#define VX128_P_MASK VX(0x3f, 0x630)
+
+#define VX128_4(op, xop) (OP (op) | (((unsigned long)(xop)) & 0x730))
+#define VX128_4_MASK VX(0x3f, 0x730)
+
+#define VX128_5(op, xop) (OP (op) | (((unsigned long)(xop)) & 0x10))
+#define VX128_5_MASK VX(0x3f, 0x10)
+
 /* An X form instruction.  */
 #define X(op, xop) (OP (op) | ((((unsigned long)(xop)) & 0x3ff) << 1))
 
@@ -2723,6 +2877,7 @@
 #define PPCPS	PPC_OPCODE_PPCPS
 #define PPCVEC	PPC_OPCODE_ALTIVEC
 #define PPCVEC2	PPC_OPCODE_ALTIVEC2
+#define PPCVEC128 PPC_OPCODE_VMX_128
 #define PPCVSX	PPC_OPCODE_VSX
 #define PPCVSX2	PPC_OPCODE_VSX
 #define POWER	PPC_OPCODE_POWER
@@ -3314,6 +3469,90 @@
 {"evsubfssiaaw",VX (4,1219),	VX_MASK,     PPCSPE|PPCVLE, PPCNONE,	{RS, RA}},
 {"evmra",	VX (4,1220),	VX_MASK,     PPCSPE|PPCVLE, PPCNONE,	{RS, RA}},
 {"vxor",	VX (4,1220),	VX_MASK,     PPCVEC|PPCVLE, PPCNONE,	{VD, VA, VB}},
+
+{ "vsldoi128", VX128_5(4,   16), VX128_5_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128, SHB } },
+{ "lvsl128",   VX128_1(4,    3), VX128_1_MASK, PPCVEC128, PPCNONE, { VD128, RA, RB } },
+{ "lvsr128",   VX128_1(4,   67), VX128_1_MASK, PPCVEC128, PPCNONE, { VD128, RA, RB } },
+{ "lvewx128",  VX128_1(4,  131), VX128_1_MASK, PPCVEC128, PPCNONE, { VD128, RA, RB } },
+{ "lvx128",    VX128_1(4,  195), VX128_1_MASK, PPCVEC128, PPCNONE, { VD128, RA, RB } },
+{ "stvewx128", VX128_1(4,  387), VX128_1_MASK, PPCVEC128, PPCNONE, { VS128, RA, RB } },
+{ "stvx128",   VX128_1(4,  451), VX128_1_MASK, PPCVEC128, PPCNONE, { VS128, RA, RB } },
+{ "lvxl128",   VX128_1(4,  707), VX128_1_MASK, PPCVEC128, PPCNONE, { VD128, RA, RB } },
+{ "stvxl128",  VX128_1(4,  963), VX128_1_MASK, PPCVEC128, PPCNONE, { VS128, RA, RB } },
+{ "lvlx128",   VX128_1(4, 1027), VX128_1_MASK, PPCVEC128, PPCNONE, { VD128, RA, RB } },
+{ "lvrx128",   VX128_1(4, 1091), VX128_1_MASK, PPCVEC128, PPCNONE, { VD128, RA, RB } },
+{ "stvlx128",  VX128_1(4, 1283), VX128_1_MASK, PPCVEC128, PPCNONE, { VS128, RA, RB } },
+{ "stvrx128",  VX128_1(4, 1347), VX128_1_MASK, PPCVEC128, PPCNONE, { VS128, RA, RB } },
+{ "lvlxl128",  VX128_1(4, 1539), VX128_1_MASK, PPCVEC128, PPCNONE, { VD128, RA, RB } },
+{ "lvrxl128",  VX128_1(4, 1603), VX128_1_MASK, PPCVEC128, PPCNONE, { VD128, RA, RB } },
+{ "stvlxl128", VX128_1(4, 1795), VX128_1_MASK, PPCVEC128, PPCNONE, { VS128, RA, RB } },
+{ "stvrxl128", VX128_1(4, 1859), VX128_1_MASK, PPCVEC128, PPCNONE, { VS128, RA, RB } },
+
+{ "vperm128",   VX128_2(5, 0), VX128_2_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128, VC128 } },
+{ "vaddfp128",  VX128(5,  16), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vsubfp128",  VX128(5,  80), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vmulfp128",  VX128(5, 144), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vmaddfp128", VX128(5, 208), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128, VS128 } },
+{ "vmaddcfp128",VX128(5, 272), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VS128, VB128 } },
+{ "vnmsubfp128",VX128(5, 336), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128, VS128 } },
+{ "vmsum3fp128",VX128(5, 400), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vmsum4fp128",VX128(5, 464), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vpkshss128", VX128(5, 512), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vand128",    VX128(5, 528), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vpkshus128", VX128(5, 576), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vandc128",   VX128(5, 592), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vpkswss128", VX128(5, 640), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vnor128",    VX128(5, 656), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vpkswus128", VX128(5, 704), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vor128",     VX128(5, 720), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vpkuhum128", VX128(5, 768), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vxor128",    VX128(5, 784), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vpkuhus128", VX128(5, 832), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vsel128",    VX128(5, 848), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128, VS128 } },
+{ "vpkuwum128", VX128(5, 896), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vslo128",    VX128(5, 912), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vpkuwus128", VX128(5, 960), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vsro128",    VX128(5, 976), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+
+{ "vpermwi128",  VX128_P(6,  528), VX128_P_MASK, PPCVEC128, PPCNONE, { VD128, VB128, VPERM128 } },
+{ "vcfpsxws128", VX128_3(6,  560), VX128_3_MASK, PPCVEC128, PPCNONE, { VD128, VB128, SIMM } },
+{ "vcfpuxws128", VX128_3(6,  624), VX128_3_MASK, PPCVEC128, PPCNONE, { VD128, VB128, UIMM } },
+{ "vcsxwfp128",  VX128_3(6,  688), VX128_3_MASK, PPCVEC128, PPCNONE, { VD128, VB128, SIMM } },
+{ "vcuxwfp128",  VX128_3(6,  752), VX128_3_MASK, PPCVEC128, PPCNONE, { VD128, VB128, UIMM } },
+{ "vrfim128",    VX128_3(6,  816), VX128_3_MASK, PPCVEC128, PPCNONE, { VD128, VB128 } },
+{ "vrfin128",    VX128_3(6,  880), VX128_3_MASK, PPCVEC128, PPCNONE, { VD128, VB128 } },
+{ "vrfip128",    VX128_3(6,  944), VX128_3_MASK, PPCVEC128, PPCNONE, { VD128, VB128 } },
+{ "vrfiz128",    VX128_3(6, 1008), VX128_3_MASK, PPCVEC128, PPCNONE, { VD128, VB128 } },
+{ "vpkd3d128",   VX128_4(6, 1552), VX128_4_MASK, PPCVEC128, PPCNONE, { VD128, VB128, VD3D0, VD3D1, VD3D2} },
+{ "vrefp128",    VX128_3(6, 1584), VX128_3_MASK, PPCVEC128, PPCNONE, { VD128, VB128 } },
+{ "vrsqrtefp128",VX128_3(6, 1648), VX128_3_MASK, PPCVEC128, PPCNONE, { VD128, VB128 } },
+{ "vexptefp128", VX128_3(6, 1712), VX128_3_MASK, PPCVEC128, PPCNONE, { VD128, VB128 } },
+{ "vlogefp128",  VX128_3(6, 1776), VX128_3_MASK, PPCVEC128, PPCNONE, { VD128, VB128 } },
+{ "vrlimi128",   VX128_4(6, 1808), VX128_4_MASK, PPCVEC128, PPCNONE, { VD128, VB128, UIMM, VD3D2} },
+{ "vspltw128",   VX128_3(6, 1840), VX128_3_MASK, PPCVEC128, PPCNONE, { VD128, VB128, UIMM } },
+{ "vspltisw128", VX128_3(6, 1904), VX128_3_MASK, PPCVEC128, PPCNONE, { VD128, VB128, SIMM } },
+{ "vupkd3d128",  VX128_3(6, 2032), VX128_3_MASK, PPCVEC128, PPCNONE, { VD128, VB128, UIMM } },
+{ "vcmpeqfp128", VX128(6,   0), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vcmpeqfp128.",VX128(6,  64), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vrlw128",     VX128(6,  80), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vcmpgefp128", VX128(6, 128), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vcmpgefp128.",VX128(6, 192), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vslw128",     VX128(6, 208), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vcmpgtfp128", VX128(6, 256), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vcmpgtfp128.",VX128(6, 320), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vsraw128",    VX128(6, 336), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vcmpbfp128",  VX128(6, 384), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vcmpbfp128.", VX128(6, 448), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vsrw128",     VX128(6, 464), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vcmpequw128", VX128(6, 512), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vcmpequw128.",VX128(6, 576), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vmaxfp128",   VX128(6, 640), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vminfp128",   VX128(6, 704), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vmrghw128",   VX128(6, 768), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vmrglw128",   VX128(6, 832), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VA128, VB128 } },
+{ "vupkhsb128",  VX128(6, 896), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VB128 } },
+{ "vupklsb128",  VX128(6, 960), VX128_MASK, PPCVEC128, PPCNONE, { VD128, VB128 } },
+
 {"evdivws",	VX (4,1222),	VX_MASK,     PPCSPE|PPCVLE, PPCNONE,	{RS, RA, RB}},
 {"vcmpeqfp.",	VXR(4, 198,1),	VXR_MASK,    PPCVEC|PPCVLE, PPCNONE,	{VD, VA, VB}},
 {"udi3fcm.",	APU(4, 611,0), APU_MASK, PPC405|PPC440, PPC476,		{URT, URA, URB}},
@@ -5375,7 +5614,7 @@
 
 {"bblels",	X(31,518),	X_MASK,      PPCBRLK,	PPCNONE,	{0}},
 
-{"lvlx",	X(31,519),	X_MASK,      CELL,	PPCNONE,	{VD, RA0, RB}},
+{"lvlx",	X(31,519),	X_MASK,      CELL|PPCVEC128,	PPCNONE,	{VD, RA0, RB}},
 {"lbfcmux",	APU(31,519,0), 	APU_MASK,    PPC405,	PPCNONE,	{FCRT, RA, RB}},
 
 {"subfco",	XO(31,8,1,0),	XO_MASK,     PPCCOM|PPCVLE, PPCNONE,	{RT, RA, RB}},
@@ -5424,7 +5663,7 @@
 
 {"bbelr",	X(31,550),	X_MASK,      PPCBRLK,	PPCNONE,	{0}},
 
-{"lvrx",	X(31,551),	X_MASK,      CELL,	PPCNONE,	{VD, RA0, RB}},
+{"lvrx",	X(31,551),	X_MASK,      CELL|PPCVEC128,	PPCNONE,	{VD, RA0, RB}},
 {"lhfcmux",	APU(31,551,0), 	APU_MASK,    PPC405,	PPCNONE,	{FCRT, RA, RB}},
 
 {"subfo",	XO(31,40,1,0),	XO_MASK,     PPC,	PPCNONE,	{RT, RA, RB}},
@@ -5483,7 +5722,7 @@
 
 {"stbdx",	X(31,643),	X_MASK,      E500MC,	PPCNONE,	{RS, RA, RB}},
 
-{"stvlx",	X(31,647),	X_MASK,      CELL,	PPCNONE,	{VS, RA0, RB}},
+{"stvlx",	X(31,647),	X_MASK,      CELL|PPCVEC128,	PPCNONE,	{VS, RA0, RB}},
 {"stbfcmux",	APU(31,647,0), 	APU_MASK,    PPC405,	PPCNONE,	{FCRT, RA, RB}},
 
 {"stxsspx",	X(31,652),	XX1_MASK,    PPCVSX2,	PPCNONE,	{XS6, RA0, RB}},
@@ -5522,7 +5761,7 @@
 
 {"stvfrx",	X(31,677),	X_MASK,      PPCVEC2,	PPCNONE,	{VS, RA0, RB}},
 
-{"stvrx",	X(31,679),	X_MASK,      CELL,	PPCNONE,	{VS, RA0, RB}},
+{"stvrx",	X(31,679),	X_MASK,      CELL|PPCVEC128,	PPCNONE,	{VS, RA0, RB}},
 {"sthfcmux",	APU(31,679,0), 	APU_MASK,    PPC405,	PPCNONE,	{FCRT, RA, RB}},
 
 {"tendall.",	XRC(31,686,1)|(1<<25), XRTRARB_MASK, PPCHTM, PPCNONE,	{0}},
@@ -5609,7 +5848,7 @@
 
 {"lvsm",	X(31,773),	X_MASK,      PPCVEC2,	PPCNONE,	{VD, RA0, RB}},
 {"stvepxl",	X(31,775),	X_MASK,      PPCVEC2,	PPCNONE,	{VS, RA0, RB}},
-{"lvlxl",	X(31,775),	X_MASK,      CELL,	PPCNONE,	{VD, RA0, RB}},
+{"lvlxl",	X(31,775),	X_MASK,      CELL|PPCVEC128,	PPCNONE,	{VD, RA0, RB}},
 {"ldfcmux",	APU(31,775,0), 	APU_MASK,    PPC405,	PPCNONE,	{FCRT, RA, RB}},
 
 {"dozo",	XO(31,264,1,0),	XO_MASK,     M601,	PPCNONE,	{RT, RA, RB}},
@@ -5645,7 +5884,7 @@
 
 {"lvtrxl",	X(31,805),	X_MASK,      PPCVEC2,	PPCNONE,	{VD, RA0, RB}},
 {"stvepx",	X(31,807),	X_MASK,      PPCVEC2,	PPCNONE,	{VS, RA0, RB}},
-{"lvrxl",	X(31,807),	X_MASK,      CELL,	PPCNONE,	{VD, RA0, RB}},
+{"lvrxl",	X(31,807),	X_MASK,      CELL|PPCVEC128,	PPCNONE,	{VD, RA0, RB}},
 
 {"tabortdc.",	XRC(31,814,1),	X_MASK,      PPCHTM,	PPCNONE,	{TO, RA, RB}},
 
@@ -5704,7 +5943,7 @@
 
 {"lfiwzx",	X(31,887),	X_MASK,   POWER7|PPCA2,	PPCNONE,	{FRT, RA0, RB}},
 
-{"stvlxl",	X(31,903),	X_MASK,      CELL,	PPCNONE,	{VS, RA0, RB}},
+{"stvlxl",	X(31,903),	X_MASK,      CELL|PPCVEC128,	PPCNONE,	{VS, RA0, RB}},
 {"stdfcmux",	APU(31,903,0), 	APU_MASK,    PPC405,	PPCNONE,	{FCRT, RA, RB}},
 
 {"divdeuo",	XO(31,393,1,0),	XO_MASK,  POWER7|PPCA2,	PPCNONE,	{RT, RA, RB}},
@@ -5747,7 +5986,7 @@
 {"wclrall",	X(31,934),	XRARB_MASK,  PPCA2,	PPCNONE,	{L}},
 {"wclr",	X(31,934),	X_MASK,	     PPCA2,	PPCNONE,	{L, RA0, RB}},
 
-{"stvrxl",	X(31,935),	X_MASK,      CELL,	PPCNONE,	{VS, RA0, RB}},
+{"stvrxl",	X(31,935),	X_MASK,      CELL|PPCVEC128,	PPCNONE,	{VS, RA0, RB}},
 
 {"divdeo",	XO(31,425,1,0),	XO_MASK,  POWER7|PPCA2,	PPCNONE,	{RT, RA, RB}},
 {"divdeo.",	XO(31,425,1,1),	XO_MASK,  POWER7|PPCA2,	PPCNONE,	{RT, RA, RB}},
